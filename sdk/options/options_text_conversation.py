import torch
from sdk.options import Options, Devices
from typing import Optional, Union, Dict, Any
from transformers import ModelCard


class OptionsTextConversation(Options):
    """
    Options for text-Generation models
    """
    """
    Initializes the OptionsTextConversation.

    Args:
        prompt (str): The prompt or starting text for text generation.
        model_name (str): The name of the model to use for text generation.
        create_new_conv (bool): Whether to create a new conversation.
            Default is False.
        create_new_tokenizer (bool): Whether to create a new tokenizer.
            Default is False.
        delete_conv (bool): Whether to delete a conversation.
            Default is False.
        delete_tokenizer (bool): Whether to delete a tokenizer.
            Default is False.
        model_card (Optional[Union[str, ModelCard]]): The model card
            providing details about the model.
        framework (Optional[str]): The deep learning framework used for
            the model, such as 'torch' or 'tf'.
        task (str): The task for which the model is being used.
            Default is an empty string.
        num_workers (int): The number of worker processes for data loading.
            Default is 8.
        batch_size (int): The batch size for inference. Default is 1.
        device (Union[str, Devices]): The device to use for inference,
            specified from the `Devices` enum.
        arg_parser (Optional[Dict[str, Any]]): Optional additional
            arguments for the model.
        torch_dtype (Optional[Union[str, torch.dtype]]): The data type for
            PyTorch tensors, such as 'float32' or 'float64'.
        binary_output (bool): Whether the output should be binary or text.
            Default is False.
        min_length_for_response (int): The minimum length of response
            generated by the model. Default is 32.
        minimum_tokens (int): The minimum number of tokens required for
            a valid response. Default is 10.
        attention_mask (bool): Whether to use attention mask.
            Default is True.
        pad_token_id (int): The ID of the padding token. Default is 50256.
        eos_token_id (int): The ID of the end-of-sequence token.
            Default is 50256.
        tokenizer_id_to_use (int): The ID of the tokenizer to use.
            Default is 0.
        chat_id_to_use (int): The ID of the conversation to use.
            Default is 0.
    """
    def __init__(self,
                 prompt: str,
                 model_name: str,
                 create_new_conv: bool = False,
                 delete_conv: bool = False,
                 delete_tokenizer: bool = False,
                 model_card: Optional[Union[str, ModelCard]] = None,
                 framework: Optional[str] = None,
                 task: str = "",
                 num_workers: int = 8,
                 batch_size: int = 1,
                 device: Union[str, Devices] = -1,
                 arg_parser: Optional[Dict[str, Any]] = None,
                 torch_dtype: Optional[Union[str, torch.dtype]] = None,
                 binary_output: bool = False,
                 min_length_for_response: int = 32,
                 minimum_tokens: int = 10,
                 attention_mask: bool = True,
                 pad_token_id: int = 50256,
                 eos_token_id: int = 50256,
                 tokenizer_id_to_use: int = 0,
                 chat_id_to_use: int = 0,
                 trust_remote_code: bool = False
                 ):

        super().__init__(device)
        self.prompt = prompt
        self.task = task
        self.model_name = model_name
        if model_card:
            self.model_card = model_card
        self.num_workers = num_workers
        self.batch_size = batch_size
        if framework:
            self.framework = framework
        if arg_parser:
            self.arg_parser = arg_parser
        if torch_dtype:
            self.torch_dtype = torch_dtype
        self.torch_dtype = torch_dtype
        self.binary_output = binary_output
        self.min_length_for_response = min_length_for_response
        self.minimum_tokens = minimum_tokens
        self.attention_mask = attention_mask
        self.pad_token_id = pad_token_id
        self.eos_token_id = eos_token_id
        self.create_new_conv = create_new_conv
        self.delete_tokenizer = delete_tokenizer
        self.delete_conv = delete_conv
        self.tokenizer_id_to_use = tokenizer_id_to_use
        self.chat_id_to_use = chat_id_to_use
        self.trust_remote_code = trust_remote_code

